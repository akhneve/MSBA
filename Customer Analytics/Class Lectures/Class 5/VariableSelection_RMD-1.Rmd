---
title: "Variable Selection"
output:
  word_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


## First Steps 

NOTE: Your data needs to be in the folder where your code is located!

The first Chunk of Code will always do 3 Things for us

1) Clear ALL Variables (to make sure nothing is "left over") and clear the      screen. 
2) Read in the data we want to use. In our case the file is called              "Data_VariableSelection_R.csv"
3) Explore the data (what variables are in it and what are some basic           statistics for these variables)

```{r}

# Clear All Variables & Clear Screen
rm(list=ls())
cat("\014")

# Read in the Data
data.all.vs  = read.csv("Data_VariableSelection_v7_R.csv")
data.vs      = data.all.vs[1:300,]
data.test.vs = data.all.vs[301:400,]


# Explore the data
str(data.vs)
summary(data.vs)
```


## VARIABLE SELECTION REGRESSION MODEL

1) Define y (Dependent Variable). For this example, y is used

2) Define X (Independent Variables). For this example, x1-x16 are used

3) Variable Selection by Stepwise Regression. Note instead of writing y~x1+x2+x3+... one can simply write y~. and the model will use all data in the current dataset (in our case, data.vs) that is not called 'y'

```{r}

# Need to load and open package 'MASS'
# install.packages('MASS')
library(MASS)

# Run FULL Model
model.full <- lm(y~.,data=data.vs)
# Run INTERCEPT ONLY Model
model.int  <- lm(y~1,data=data.vs)

# Run Variable Selection Models
model.vs_forward   <-stepAIC(model.int,direction="forward",scope=list(upper=model.full,lower=model.int))
model.vs_backward  <- stepAIC(model.full, direction="backward")

# Display the Results
summary(model.vs_forward)
summary(model.vs_backward)
summary(model.full)

# Caculate Test Performance 
testing.vs_forward  <- data.frame(y = predict(model.vs_forward, data.test.vs))
testing.vs_backward <- data.frame(y = predict(model.vs_backward, data.test.vs))
testing.full        <- data.frame(y = predict(model.full, data.test.vs))

# Caculate Training and Testing Performance using Mean Squared Error (MSE)
# install.packages("MLmetrics")
library(MLmetrics)
mse.training.forward  = MSE(y_pred = model.vs_forward$fitted.values, y_true = data.vs$y)
mse.training.backward = MSE(y_pred = model.vs_backward$fitted.values, y_true = data.vs$y)
mse.training.full     = MSE(y_pred = model.full$fitted.values, y_true = data.vs$y)
mse.testing.forward   = MSE(y_pred = testing.vs_forward$y, y_true = data.test.vs$y)
mse.testing.backward  = MSE(y_pred = testing.vs_backward$y, y_true = data.test.vs$y)
mse.testing.full      = MSE(y_pred = testing.full$y, y_true = data.test.vs$y)


```


## An Different Approach to the same Problem

Using a tree-based Model 

```{r}

# Another Type of VS with ML - Stochastic Gradient Boosting Machine
# Often also called MART - Multiple Additive Regression Trees
# This is one of the most used ML models as very flexible
# install.packages('gbm')
library(gbm)

# TRAINING
gbm1 <- gbm(y~., distribution = "gaussian",data = data.vs,n.trees =  10000,cv.folds = 5)

summary(gbm1)

# R^2 
SS.tot <- sum((data.vs$y-mean(data.vs$y))^2)
SS.res <- sum((gbm1$fit-data.vs$y)^2)
CV_RSq = 1-SS.res/SS.tot

# Caculate Test Performance 
testing.gbm  <- data.frame(y = predict(gbm1, data.test.vs))

# Caculate Testing Performance using Mean Squared Error (MSE)
mse.training.gbm  = MSE(y_pred = gbm1$fit, y_true = data.vs$y)
mse.testing.gbm  = MSE(y_pred = testing.gbm$y, y_true = data.test.vs$y)


```


```{r}

# Visual Comparison of the Training Performance
par(mfrow=c(2,2))
plot(data.vs$y, model.vs_forward$fitted.values, main="Training Data - Forward", xlab="Data ", ylab="Fitted Data", pch=19)
plot(data.test.vs$y, testing.vs_forward$y, main="Testing Data - Forward", xlab="Data ", ylab="Fitted Data", pch=19)
plot(data.vs$y, model.vs_backward$fitted.values, main="Training Data - Backward", xlab="Data ", ylab="Fitted Data", pch=19)
plot(data.test.vs$y, testing.vs_backward$y, main="Testing Data - Backward", xlab="Data ", ylab="Fitted Data", pch=19)

# Visual Comparison of the Training Performance
par(mfrow=c(2,2))
plot(data.vs$y, model.full$fitted.values, main="Training Data - Full", xlab="Data ", ylab="Fitted Data", pch=19)
plot(data.test.vs$y, testing.full$y, main="Testing Data - Full", xlab="Data ", ylab="Fitted Data", pch=19)
plot(data.vs$y, gbm1$fit, main="Training Data - GBM", xlab="Data ", ylab="Fitted Data", pch=19)
plot(data.test.vs$y, testing.gbm$y, main="Testing Data - GBM",xlab="Data ", ylab="Fitted Data", pch=19)


# Fit Comparison of Training Performance
mse <- matrix(c(mse.training.forward,mse.training.backward,mse.training.full,mse.training.gbm,mse.testing.forward,mse.testing.backward,mse.testing.full,mse.testing.gbm),ncol=2,nrow=4)
rownames(mse) <- c("Forward","Backward","Full","GBM")
colnames(mse) <- c("Training","Testing")

# install.packages("formattable")
library(formattable)
formattable(mse)

```
